{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np  \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom sklearn import svm\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom mlxtend.plotting import plot_confusion_matrix\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\nimport os\nprint(os.listdir(\"../input\"))\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/creditcardfraud/creditcard.csv\")\ndata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n#unbalace of the data using bar graph\ncount = pd.value_counts(data['Class'], sort = True).sort_index()\ncount.plot(kind = 'bar')\nplt.title('Unbalance Data')\nplt.xlabel('Class')\nplt.ylabel('Frequency')\nplt.show()\n\n# unbalace of the data using pie chart\ncount = pd.value_counts(data['Class'], sort = True).sort_index()\ncount.plot(kind = 'pie')\nplt.title('Unbalance Data')\nplt.show()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"No_of_frauds= len(data[data[\"Class\"]==1])\nNo_of_normals = len(data[data[\"Class\"]==0])\ntotal= No_of_frauds + No_of_normals\nFraud_percent= (No_of_frauds / total)*100\nNormal_percent= (No_of_normals / total)*100\n\nprint(\"The number of normal transactions(Class 0) are: \", No_of_normals)\nprint(\"The number of fraudulent transactions(Class 1) are: \", No_of_frauds)\nprint(\"Class 0 percentage = \", Normal_percent)\nprint(\"Class 1 percentage = \", Fraud_percent)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Resampleing the dataset\ndata['normAmount']=StandardScaler().fit_transform(data['Amount'].values.reshape(-1,1))\nX=data.drop(['Time','Amount'],axis=1)\ny=data['Class']\n\n# Split the data into training and testing subsets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 12)\n\n# show the dimensions of the train/test data\nprint(\"X_train.shape: \", X_train.shape)\nprint(\"X_test.shape: \", X_test.shape)\nprint(\"y_train.shape: \", y_train.shape)\nprint(\"y_test.shape: \", y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"normal_class = data[data.Class == 0]\nfraud_class = data[data.Class == 1]\nundersampled_data = pd.concat([normal_class.sample(frac = (len(fraud_class)/len(normal_class))), fraud_class.sample(frac=1)],axis=0)\nX = pd.DataFrame(undersampled_data.iloc[:,undersampled_data.columns!='Class'])\ny = undersampled_data.iloc[:,undersampled_data.columns == 'Class']\n\n\nsc = StandardScaler()\nX[\"scaled_Amount\"]=  sc.fit_transform(X.iloc[:,29].values.reshape(-1,1))\nX= X.drop([\"Time\",\"Amount\"], axis= 1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 0)\n\nclassifier= SVC(C= 10, kernel= 'rbf', random_state= 0)\nclassifier.fit(X_train, np.array(y_train).ravel())\n\ny_pred = classifier.predict(X_test)\n\n\ncm = confusion_matrix(y_test, y_pred)\nprint(\"The accuracy is \"+str((cm[1,1]+cm[0,0])/(cm[0,0] + cm[0,1]+cm[1,0] + cm[1,1])*100) + \" %\")\nprint(\"The recall is \"+ str(cm[1,1]/(cm[1,0] + cm[1,1])*100) +\" %\")\nprint(\"The precision is \"+ str(cm[1,1]/(cm[0,1] + cm[1,1])*100) +\" %\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = np.array(confusion_matrix(y_test, y_pred, labels=[1,0]))\nconfusion = pd.DataFrame(cm, index=['is Fraud', 'is Normal'],columns=['predicted fraud','predicted normal'])\nconfusion\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}